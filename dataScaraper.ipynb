{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb3b399-0a1d-4c12-aa1f-e3eb22bbf670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory  /Users/leducanh/Documents/pythonProject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory \" , os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12c416d1-7667-4aa6-be0e-728d10248f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, mainUrl):\n",
    "        self.links = {\n",
    "            'categories': [],\n",
    "            'pages': {},\n",
    "            'jobOffers': []\n",
    "        }\n",
    "        self.data = {\n",
    "            'jobTitles': [],\n",
    "            'company': [],\n",
    "            'salaryRange': [],\n",
    "            'afterBonusSal': [],\n",
    "            'category+progLang': [],\n",
    "            'seniority': [],\n",
    "            'workLanguage': [],\n",
    "            'location': [],\n",
    "            'remote':[],\n",
    "            'postingTime':[]\n",
    "        }\n",
    "        self.mainUrl = mainUrl\n",
    "        self.categList = []\n",
    "\n",
    "    # getting the links for job categories\n",
    "    def getUrlByCat(self, url):\n",
    "\n",
    "        response = requests.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        linksByCat = soup.find_all('div',\n",
    "                                   class_=\"d-flex justify-content-between align-items-center list-title-wrapper ng-star-inserted\")\n",
    "        urlList = [url + href.a['href'] for href in linksByCat]\n",
    "        # removing redundant links in urlList\n",
    "        self.links['categories'] = [link for link in urlList if '?criteria' not in link]\n",
    "\n",
    "        #get a list of job categories, which will be used as keys in the links['pages'], links['jobOffers'] dictionary\n",
    "        self.categList = [self.links['categories'][i].rsplit('/', 1)[-1] for i in range(len(self.links['categories']))]\n",
    "        print('categorical urls success')\n",
    "\n",
    "    def getPages(self):\n",
    "        ''' fill the self.links['pages'], where categories are denoted as keys with the value being a list containing\n",
    "                 the link to the first page of job offers of the particular category\n",
    "                 later, the idea will be to append these lists, with the links to the next job offer pages'''\n",
    "\n",
    "        self.links['pages'] = {k: [v] for v, k in zip(self.links['categories'], self.categList)}\n",
    "\n",
    "        '''e.g. links['pages'] = {'backend': ['https://nofluffjobs.com/cz/it-prace/backend'], \n",
    "                                  'frontend': ['https://nofluffjobs.com/cz/it-prace/frontend'],\n",
    "                                   ...}'''\n",
    "\n",
    "        # adding the page url from the next button (first url page is already added)\n",
    "        for url in self.links['pages'].values():\n",
    "            while True:\n",
    "                try:\n",
    "                    response = requests.get(url[-1])\n",
    "                    soup = BeautifulSoup(response.text, 'lxml')\n",
    "                    pageLink = self.mainUrl + soup.find('a', {'aria-label': 'Next'}).get('href')\n",
    "                    url.append(pageLink)\n",
    "                except AttributeError:\n",
    "                    break\n",
    "                time.sleep(0.2)\n",
    "                response = requests.get(pageLink)\n",
    "                #soup = BeautifulSoup(response.text, 'lxml')\n",
    "        print('page urls success')\n",
    "\n",
    "    def getJobLinks(self):\n",
    "        #add keys based on job categories to the self.links['jobOffers'] dictionary  ,the values are emtpy lists\n",
    "        #self.links['jobOffers'] = {k: [] for k in self.categList}\n",
    "        #pageLinks is a dictionary with key: list values, where key is the job category and lists contain links for the pages\n",
    "        for lists in self.links['pages'].values():\n",
    "            for link in lists:\n",
    "                time.sleep(0.1)\n",
    "                # request applied on a particular page\n",
    "                response = requests.get(link).text\n",
    "                soup = BeautifulSoup(response, 'lxml')\n",
    "                #select all the 'a' tags on the particular page with the idea to capture all the 'hrefs' from there\n",
    "                aTags = soup.select(\n",
    "                    'body > nfj-root > nfj-layout > nfj-main-content > div > div.main-content__outlet.mb-5.pb-5 >nfj-postings-search > div > common-main-loader > div > nfj-search-results > nfj-postings-list:nth-child(1) >div.list-container.ng-star-inserted>a')\n",
    "\n",
    "                #looping through the 'a' tags to capture the 'hrefs' which are than added into the 'jobOffers' dictionary's list\n",
    "                #keys denotes the job category, where the particular 'href' belongs to\n",
    "                for href in aTags:\n",
    "                    self.links['jobOffers'].append(self.mainUrl + href.get('href'))\n",
    "        print('job sites url success')\n",
    "    def getData(self):\n",
    "        for link in self.links['jobOffers']:    \n",
    "            time.sleep(0.2)\n",
    "            response = requests.get(link)\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            #getting job titles\n",
    "            jobTitle = soup.find('div',\n",
    "                                 class_=\"posting-details-description d-flex align-items-center align-items-lg-start flex-column justify-content-center justify-content-lg-start\")\n",
    "            try:\n",
    "                self.data['jobTitles'].append(jobTitle.h1.text)\n",
    "            except:\n",
    "                self.data['jobTitles'].append(None)\n",
    "            self.data['company'].append(jobTitle.a.text)\n",
    "\n",
    "            #getting offered salary ranges\n",
    "            salaryRange = soup.find('div', class_=\"salary\")\n",
    "            self.data['salaryRange'].append(salaryRange.h4.text)\n",
    "\n",
    "            #getting salaries after bonus\n",
    "            bonus = soup.find('span', class_=\"bonus-value color-main\")\n",
    "            try:\n",
    "                self.data['afterBonusSal'].append(bonus.text)\n",
    "            # afterBonusSal equals to salaryRange\n",
    "            except:\n",
    "                self.data['afterBonusSal'].append(salaryRange.h4.text)\n",
    "\n",
    "            #getting job's location\n",
    "            location = soup.find('common-posting-locations')\n",
    "            try:\n",
    "                self.data['location'].append(location.text)\n",
    "            except:\n",
    "                self.data['location'].append(None)\n",
    "            \n",
    "            #getting the info, whether it is a remote job\n",
    "            remote = soup.find('li', class_=\"remote\")\n",
    "            try:\n",
    "                self.data['remote'].append(remote.text)\n",
    "            except:\n",
    "                self.data['remote'].append(None)\n",
    "            \n",
    "            #getting info on the posting time of the job offer\n",
    "            postingTime = soup.find('div', class_= 'posting-time-row')\n",
    "            self.data['postingTime'].append(postingTime.text)\n",
    "            \n",
    "\n",
    "            #getting offered job category (type of job + the main language\n",
    "            #we will get 2 divs from the find_all, each div representing a row on the website\n",
    "            basicInfos = soup.find_all('div',\n",
    "                                        class_=\"posting-info-row d-flex flex-column flex-md-row justify-content-between justify-content-center align-items-md-center\")\n",
    "\n",
    "            for index, info in enumerate(basicInfos):\n",
    "                # if we are scraping from the upper row\n",
    "                if index % 2 == 0:\n",
    "                    # getting job category+language or work language (=english or czech)\n",
    "                    spanBasicInfo = info.find('span', class_='font-weight-semi-bold')\n",
    "                    self.data['category+progLang'].append(spanBasicInfo.text)\n",
    "\n",
    "                    spanSenior = info.find('span', class_=\"mr-10 font-weight-medium\")\n",
    "                    self.data['seniority'].append(spanSenior.text)\n",
    "                else:\n",
    "                    try:\n",
    "                        spanWorkLang = info.find('span', class_='font-weight-semi-bold')\n",
    "                        self.data['workLanguage'].append(spanWorkLang.text)\n",
    "                    except:\n",
    "                        self.data['workLanguage'].append(None)\n",
    "        print('data extraction success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7eb3627d-f63e-43b9-9246-6abe402813b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical urls success\n",
      "page urls success\n",
      "job sites url success\n",
      "data extraction success\n"
     ]
    }
   ],
   "source": [
    "mainUrl = 'https://nofluffjobs.com'\n",
    "\n",
    "site = Scraper(mainUrl)\n",
    "\n",
    "site.getUrlByCat(mainUrl)\n",
    "\n",
    "site.getPages()\n",
    "\n",
    "site.getJobLinks()\n",
    "\n",
    "site.getData()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c784002c-478d-485c-a86d-292b6c4609c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobTitles</th>\n",
       "      <th>company</th>\n",
       "      <th>salaryRange</th>\n",
       "      <th>afterBonusSal</th>\n",
       "      <th>category+progLang</th>\n",
       "      <th>seniority</th>\n",
       "      <th>workLanguage</th>\n",
       "      <th>location</th>\n",
       "      <th>remote</th>\n",
       "      <th>postingTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Java Developer - zdravotnictví, letectví</td>\n",
       "      <td>Randstad HR Solutions s.r.o.</td>\n",
       "      <td>70k  - 90k  CZK</td>\n",
       "      <td>70k  - 90k  CZK</td>\n",
       "      <td>Backend, java</td>\n",
       "      <td>Mid</td>\n",
       "      <td>česky</td>\n",
       "      <td>Praha, Plzeň • Praha• Plzeň</td>\n",
       "      <td>None</td>\n",
       "      <td>Tato nabídka byla zveřejněna dnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Solution Architect</td>\n",
       "      <td>Randstad HR Solutions s.r.o.</td>\n",
       "      <td>100k  - 150k  CZK</td>\n",
       "      <td>100k  - 150k  CZK</td>\n",
       "      <td>Backend, Enterprise Architect</td>\n",
       "      <td>Mid, Senior</td>\n",
       "      <td>česky</td>\n",
       "      <td>Praha • Praha</td>\n",
       "      <td>None</td>\n",
       "      <td>Tato nabídka byla zveřejněna dnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C++ Embedded - automotive</td>\n",
       "      <td>Randstad HR Solutions s.r.o.</td>\n",
       "      <td>75k  - 100k  CZK</td>\n",
       "      <td>75k  - 100k  CZK</td>\n",
       "      <td>Backend, c++</td>\n",
       "      <td>Mid</td>\n",
       "      <td>česky,</td>\n",
       "      <td>Praha • Praha</td>\n",
       "      <td>None</td>\n",
       "      <td>Tato nabídka byla zveřejněna dnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Engineer Node.js</td>\n",
       "      <td>OAK'S LAB</td>\n",
       "      <td>75k  - 150k  CZK</td>\n",
       "      <td>75k  - 150k  CZK</td>\n",
       "      <td>Backend, node</td>\n",
       "      <td>Senior</td>\n",
       "      <td>česky</td>\n",
       "      <td>Prague, Old Town Square 604/14 (Po pandemi)• ...</td>\n",
       "      <td>Covid-time na dálku</td>\n",
       "      <td>Tato nabídka byla zveřejněna dnes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Backend Engineer (Node.js)</td>\n",
       "      <td>OAK'S LAB</td>\n",
       "      <td>70k  - 140k  CZK</td>\n",
       "      <td>70k  - 140k  CZK</td>\n",
       "      <td>Backend, NodeJS</td>\n",
       "      <td>Mid</td>\n",
       "      <td>česky</td>\n",
       "      <td>Prague, Old Town Square 604/14 (Po pandemi)• ...</td>\n",
       "      <td>Covid-time na dálku</td>\n",
       "      <td>Tato nabídka byla zveřejněna dnes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    jobTitles                         company  \\\n",
       "0   Java Developer - zdravotnictví, letectví    Randstad HR Solutions s.r.o.    \n",
       "1                         Solution Architect    Randstad HR Solutions s.r.o.    \n",
       "2                  C++ Embedded - automotive    Randstad HR Solutions s.r.o.    \n",
       "3                      Lead Engineer Node.js                       OAK'S LAB    \n",
       "4                 Backend Engineer (Node.js)                       OAK'S LAB    \n",
       "\n",
       "           salaryRange        afterBonusSal              category+progLang  \\\n",
       "0     70k  - 90k  CZK      70k  - 90k  CZK                   Backend, java   \n",
       "1   100k  - 150k  CZK    100k  - 150k  CZK   Backend, Enterprise Architect   \n",
       "2    75k  - 100k  CZK     75k  - 100k  CZK                    Backend, c++   \n",
       "3    75k  - 150k  CZK     75k  - 150k  CZK                   Backend, node   \n",
       "4    70k  - 140k  CZK     70k  - 140k  CZK                 Backend, NodeJS   \n",
       "\n",
       "       seniority workLanguage  \\\n",
       "0           Mid         česky   \n",
       "1   Mid, Senior         česky   \n",
       "2           Mid       česky,    \n",
       "3        Senior         česky   \n",
       "4           Mid         česky   \n",
       "\n",
       "                                            location                 remote  \\\n",
       "0                       Praha, Plzeň • Praha• Plzeň                    None   \n",
       "1                                     Praha • Praha                    None   \n",
       "2                                     Praha • Praha                    None   \n",
       "3   Prague, Old Town Square 604/14 (Po pandemi)• ...   Covid-time na dálku    \n",
       "4   Prague, Old Town Square 604/14 (Po pandemi)• ...   Covid-time na dálku    \n",
       "\n",
       "                           postingTime  \n",
       "0   Tato nabídka byla zveřejněna dnes   \n",
       "1   Tato nabídka byla zveřejněna dnes   \n",
       "2   Tato nabídka byla zveřejněna dnes   \n",
       "3   Tato nabídka byla zveřejněna dnes   \n",
       "4   Tato nabídka byla zveřejněna dnes   "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(site.data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2f4784f-131a-4a5f-ad6a-8df06cc2240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('jobOffers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
